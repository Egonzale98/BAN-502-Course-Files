---
output:
  word_document: default
  html_document: default
---
Libraries

```{r, include = FALSE}
library(tidyverse)
library(tidymodels)
library(caret)
library(gridExtra)
library(vip) #variable importance
library(ranger) #for random forests
```

```{r}
drug = read_csv("drug_data-1.csv")
```

```{r}
names(drug) = c("ID", "Age", "Gender", "Education", "Country", "Ethnicity",
"Nscore", "Escore", "Oscore", "Ascore", "Cscore", "Impulsive",
"SS", "Alcohol", "Amphet", "Amyl", "Benzos", "Caff", "Cannabis",
"Choc", "Coke", "Crack", "Ecstasy", "Heroin", "Ketamine", "Legalh",
"LSD", "Meth", "Mushrooms", "Nicotine", "Semer", "VSA")
#str(drug)
```

```{r}
drug[drug == "CL0"] = "No"
drug[drug == "CL1"] = "No"
drug[drug == "CL2"] = "Yes"
drug[drug == "CL3"] = "Yes"
drug[drug == "CL4"] = "Yes"
drug[drug == "CL5"] = "Yes"
drug[drug == "CL6"] = "Yes"
```

```{r}
drug_clean = drug %>% mutate_at(vars(Age:Ethnicity), funs(as_factor)) %>%
mutate(Age = factor(Age, labels = c("18_24", "25_34", "35_44",
"45_54", "55_64", "65_"))) %>%
mutate(Gender = factor(Gender, labels = c("Male", "Female"))) %>%
mutate(Education = factor(Education, labels =
c("Under16", "At16", "At17", "At18", "SomeCollege",
"ProfessionalCert", "Bachelors", "Masters", "Doctorate"))) %>%
mutate(Country = factor(Country,
labels = c("USA", "NewZealand", "Other", "Australia",
"Ireland","Canada","UK"))) %>%
mutate(Ethnicity = factor(Ethnicity,
labels = c("Black", "Asian", "White", "White/Black", "Other",
"White/Asian", "Black/Asian"))) %>%
  mutate_at(vars(Alcohol:VSA), funs(as_factor)) %>%
select(-ID)
```

```{r}
#str(drug_clean)
```

```{r}
drug_clean = drug_clean %>% select(!(Alcohol:Mushrooms)) %>% select(!(Semer:VSA))
names(drug_clean)
```

Task 1
```{r}
#summary(drug_clean)
```

We have no missing data.

Task 2
```{r}
set.seed(1234) 
drug_clean_split = initial_split(drug_clean, prop = 0.7, strata = Nicotine) #70% in training
train = training(drug_clean_split)
test = testing(drug_clean_split)
```

Task 3
```{r}
p1 = ggplot(train, aes(x = Age, fill = Nicotine)) + geom_bar(position = "fill")
p2 = ggplot(train, aes(x = Gender, fill = Nicotine)) + geom_bar(position = "fill")
p3 = ggplot(train, aes(x = Education, fill = Nicotine)) + geom_bar(position = "fill")
p4 = ggplot(train, aes(x = Country, fill = Nicotine)) + geom_bar(position = "fill")
grid.arrange(p1,p2,p3,p4)
```

Age does look to be a significant predictor of whether a person uses nicotine.
It looks like more males are nicotine users than females.
Education does not look to be a significant predictor of nicotine use.
The UK is the highest country with non-nicotine users.

```{r}
p1 = ggplot(train, aes(x = Ethnicity, fill = Nicotine)) + geom_bar(position = "fill")
p2 = ggplot(train, aes(x = Impulsive, fill = Nicotine)) + geom_bar(position = "fill")
p4 = ggplot(train, aes(x = SS, fill = Nicotine)) + geom_bar(position = "fill")
p4 = ggplot(train, aes(x = Nicotine, y = Nscore)) + geom_boxplot()
grid.arrange(p1,p2,p3,p4)
```

Black and Asian people have the least count of nicotine users.
Impulsive does seem to be a predictive variable for whether a person is a nicotine user or not. 
Escore and Nscore are not important predictors of nicotine users.

```{r}
p1 = ggplot(train, aes(x = Nicotine, y = Ascore)) + geom_boxplot()
p2 = ggplot(train, aes(x = Nicotine, y = Cscore)) + geom_boxplot()
p3 = ggplot(train, aes(x = Nicotine, y = Escore)) + geom_boxplot()
p4 = ggplot(train, aes(x = Nicotine, y = Oscore)) + geom_boxplot()
grid.arrange(p1,p2,p3,p4)
```

None of these scores look to be predictors of whether a person would be a nicotine user or not. The medians for both yes and no are about the same for all scores.

Task 4
```{r}
set.seed(123)
rf_folds = vfold_cv(train, v = 5)
```

```{r}
drug_clean_recipe = recipe(Nicotine ~., train) %>%
  step_dummy(all_nominal(), -all_outcomes())

rf_model = rand_forest(mtry = tune(), min_n = tune(), trees = 100) %>% #add tuning of mtry and min_n parameters
  #setting trees to 100 here should also speed things up a bit, but more trees might be better
  set_engine("ranger", importance = "permutation") %>% #added importance metric
  set_mode("classification")

drug_clean_wflow = 
  workflow() %>% 
  add_model(rf_model) %>% 
  add_recipe(drug_clean_recipe)

rf_grid = grid_regular(
  mtry(range = c(2, 8)), #these values determined through significant trial and error
  min_n(range = c(5, 20)), #these values determined through significant trial and error
  levels = 10
)

set.seed(123)
rf_res_tuned = tune_grid(
  drug_clean_wflow,
  resamples = rf_folds,
  grid = rf_grid #use the tuning grid
)
```

```{r}
rf_res_tuned %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  select(mean, min_n, mtry) %>%
  pivot_longer(min_n:mtry,
    values_to = "value",
    names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "Accuracy")
```
```{r}
rf_res_tuned %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  mutate(min_n = factor(min_n)) %>%
  ggplot(aes(mtry, mean, color = min_n)) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_point() +
  labs(y = "Accuracy")
```


Task 5
```{r}
best_rf = select_best(rf_res_tuned, "accuracy")

final_rf = finalize_workflow(
  drug_clean_wflow,
  best_rf
)

final_rf
```
```{r}
#fit the finalized workflow to our training data
final_rf_fit = fit(final_rf, train)
```

```{r}
final_rf_fit %>% pull_workflow_fit() %>% vip(geom = "point")
```
The SS variable is most important in this model, followed by Country UK and Oscore. 

Task 6
```{r}
trainpredrf = predict(final_rf_fit, train)
head(trainpredrf)
```
```{r}
confusionMatrix(trainpredrf$.pred_class, train$Nicotine, 
                positive = "Yes")
```

```{r}
testpredrf = predict(final_rf_fit, test)
head(testpredrf)
confusionMatrix(testpredrf$.pred_class, test$Nicotine, 
                positive = "Yes")
```

The accuracy of the model on the training set is 89.32% and the naive accuracy is 67.05%. The accuracy of the model on the testing set is 70.27% and the naive accuracy is 67.08%. The p-value on the training set is less than 0.05 while on the testing set it is 0.05766. The difference in the accuracy of the model between the training and testing sets is 19.05% which is a significant drop off. 

Task 7
I would recommend this model for real world use as it can definitely be used to predict the likelihood of an individual being a nicotine user. It would be good to examine each variable closer and look at the correlations. It is slightly concerning that there is such a large difference in the accuracy of the model on the training and testing set. 